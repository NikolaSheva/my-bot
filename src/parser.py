import requests
from bs4 import BeautifulSoup
import logging
from urllib.parse import urljoin
from typing import List
from .config import settings


logger = logging.getLogger(__name__)

class LombardParser:
    def parse(self, url: str):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –≤–æ–∑–≤—Ä–∞—Ç (html, photos)"""
        html, photos = "", []
        try:
            logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, "lxml")

            # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            title_tag = soup.find("a", class_="catalog-item--brand-title")
            title = title_tag.get_text(strip=True) if title_tag else "–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"

            subtitle_tag = soup.select_one("div.catalog-item--model")
            subtitle = subtitle_tag.get_text(strip=True) if subtitle_tag else ""

            ref_tag = soup.find("div", class_="text-gray")
            reference = ref_tag.get_text(strip=True) if ref_tag else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

            price_tag = soup.find("p", class_="item-price--text")
            price = "–ü–æ –∑–∞–ø—Ä–æ—Å—É"
            if price_tag:
                price_text = price_tag.get_text(strip=True)
                if price_text and price_text.strip():
                    price = price_text

            condition_tag = soup.find("div", class_="flex-shrink-0")
            condition = (
                condition_tag.get_text(strip=True)
                if condition_tag
                else "–°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            )

            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            characteristics = {
                "–¢–∏–ø": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–ú–∞—Ç–µ—Ä–∏–∞–ª –∫–æ—Ä–ø—É—Å–∞": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–í–æ–¥–æ–Ω–µ–ø—Ä–æ–Ω–∏—Ü–∞–µ–º–æ—Å—Ç—å": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–î–∏–∞–º–µ—Ç—Ä –∫–æ—Ä–ø—É—Å–∞": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–¶–≤–µ—Ç —Ü–∏—Ñ–µ—Ä–±–ª–∞—Ç–∞": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–ë–µ–∑–µ–ª—å": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–ú–µ—Ö–∞–Ω–∏–∑–º": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–§—É–Ω–∫—Ü–∏–∏": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–ó–∞–ø–∞—Å —Ö–æ–¥–∞": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–ö–∞–ª–∏–±—Ä": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–ú–∞—Ç–µ—Ä–∏–∞–ª —Ä–µ–º–µ—à–∫–∞": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–ö–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–°–æ—Å—Ç–æ—è–Ω–∏–µ": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                "–°—Ç–µ–∫–ª–æ": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
            }

            # –ü–∞—Ä—Å–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            for row in soup.select(
                "div.d-block.d-sm-flex.flex-nowrap.justify-space-between.align-baseline.my-2"
            ):
                label = row.find("div", class_="option-label")
                value = row.find("div", class_="option-value")
                if label and value:
                    label_text = label.get_text(strip=True).lower()
                    value_text = value.get_text(strip=True)
                    for key in characteristics:
                        if key.lower() in label_text:
                            characteristics[key] = value_text

            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–æ—Ç–æ
            img_tags = soup.select("div.catalog-item--photos__grid img")
            seen_urls = set()
            
            for img in img_tags:
                src_attr = img.get("src")
                if src_attr:
                    src_str = str(src_attr).split("?")[0].strip()
                    if (src_str and 
                        "noimage" not in src_str.lower() and 
                        not src_str.startswith("data:image")):
                        
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π URL –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π
                        full_url = urljoin(url, src_str)
                        
                        if full_url not in seen_urls:
                            seen_urls.add(full_url)
                            photos.append(full_url)
                            logger.debug(f"üì∏ –î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–æ—Ç–æ: {full_url}")

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ
            photos = photos[:10]
            # —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –±–µ–∑ custom_photos
            # photos = list(dict.fromkeys(photos))[:3]

            # –§–æ—Ä–º–∏—Ä—É–µ–º HTML
            html = f"""<a href="{url}"><b>{title}</b>  <b>{subtitle}</b></a>
<b>{reference}</b>

<b>–°–æ—Å—Ç–æ—è–Ω–∏–µ:</b> {condition}
<b>–ú–∞—Ç–µ—Ä–∏–∞–ª –∫–æ—Ä–ø—É—Å–∞:</b> {characteristics['–ú–∞—Ç–µ—Ä–∏–∞–ª –∫–æ—Ä–ø—É—Å–∞']}
<b>–§—É–Ω–∫—Ü–∏–∏:</b> {characteristics['–§—É–Ω–∫—Ü–∏–∏']}
<b>–ú–∞—Ç–µ—Ä–∏–∞–ª —Ä–µ–º–µ—à–∫–∞:</b> {characteristics['–ú–∞—Ç–µ—Ä–∏–∞–ª —Ä–µ–º–µ—à–∫–∞']}

<b>–¶–µ–Ω–∞:</b> {price}
<b>–ù–∞—à–∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã:</b> @Genesislab
–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥
+7(982)663-99-99"""

        except requests.exceptions.RequestException as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}")
            raise
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}")
            raise

        return html.strip(), photos
    

    def get_custom_photos(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö —Ñ–æ—Ç–æ"""
        return settings.custom_photos.copy()
    